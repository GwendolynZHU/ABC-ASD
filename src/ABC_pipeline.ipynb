{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pybedtools\n",
    "import pandas as pd\n",
    "import time\n",
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epigenome information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Astrocyte\n",
    "- Reference genome: ENCSR362MQF\n",
    "\n",
    "- DNase-seq accession: ENCSR000EPM, bam (MYO, FWV)\n",
    "\n",
    "- ChIP-seq H3K27ac accession: ENCSR000AOQ, bam; can be bigwig\n",
    "\n",
    "- RNA-seq: ENCSR233IJT, download tsv file\n",
    "\n",
    "- Hi-C: ENCSR011GNI, hic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cerebral cortex\n",
    "- DNase: ENCFF529PQJ_rep2, ENCFF443RWV_rep1\n",
    "\n",
    "- H3K27ac: ENCFF406PAL.bam; (82yrs male) dorsolateral prefrontal cortex available\n",
    "\n",
    "- RNA-seq: ENCFF389KXF; (75yrs) dorsolateral prefrontal cortex available (MOSTLY are 75yrs or above)\n",
    "\n",
    "- Hi-C: ENCFF925QIF (intact Hi-C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cerebellum\n",
    "- DNase: ENCFF379EFG_rep1.bam\n",
    "\n",
    "- H3K27ac: ENCFF986JMA.bigwig\n",
    "\n",
    "- RNA-seq: ENCFF668ZPO.tsv\n",
    "\n",
    "- Hi-C: astrocyte of cerebellum, same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K562\n",
    "- DNase: ENCFF205FNC_hg38_DNaseSeq_rep1\n",
    "\n",
    "- H3K27ac: ENCFF600THN_hg38_H3K27ac_rep1\n",
    "\n",
    "- RNA-seq: ENCFF928NYA.tsv\n",
    "\n",
    "- Hi-C: ENCFF080DPJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuronal stem cell\n",
    "- DNase: ENCFF224MAE_hg38_rep1.bam\n",
    "\n",
    "- H3K27ac: ENCFF805URT_H3K27ac_rep1.bam\n",
    "\n",
    "- RNA-seq: ENCFF567GQW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excitatory neurons\n",
    "- DNase: not available\n",
    "\n",
    "- ATAC-seq: motor neurons, pair-ended, ENCFF333UUT_rep1, ENCFF379GTS_rep2\n",
    "\n",
    "- H3K27ac: ENCFF698JFN_rep1\n",
    "\n",
    "- RNA-seq: ENCFF761SHW.tsv\n",
    "\n",
    "- Hi-C: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = \"Cerebral_cortex\"\n",
    "dnase_file_rep1 = \"ENCFF529PQJ.bam\"\n",
    "dnase_file_rep2 = \"ENCFF443RWV.bam\"\n",
    "# atac_file_rep1 = \"ENCFF333UUT.bam\"\n",
    "h3k27ac = \"ENCFF406PAL.bam\"\n",
    "tpm = \"ENCFF389KXF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define candidate elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call peak using macs2 and sort peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env: macs2-py2.7\n",
    "## replaced their chr.sizes file with ours (hg38)\n",
    "macs2_file = \"EncodeUwDnaseNeuronalStemAlnRep1\"\n",
    "cmds = [\"macs2 callpeak -t ../input_data/Epigenome/\"+cell_line+\"/\"+dnase_file_rep1+\" \\\n",
    "-n \"+macs2_file+\".macs2 \\\n",
    "-f BAM \\\n",
    "-g hs \\\n",
    "-p .1 \\\n",
    "--call-summits \\\n",
    "--outdir ../candidate_regions/macs2_results/\"+cell_line+\"/\", \\\n",
    "\n",
    "\"bedtools sort -faidx ../reference/chrom.sizes -i ../candidate_regions/macs2_results/\"+cell_line+\"/\"+macs2_file+\".macs2_peaks.narrowPeak > ../candidate_regions/macs2_results/\"+cell_line+\"/\"+macs2_file+\".macs2_peaks.narrowPeak.sorted\"]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(\"Executing command:\", cmd)\n",
    "\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "    # Wait for the process to finish and capture any errors\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    # Print any errors\n",
    "    if stderr:\n",
    "        print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### peak calling for ATAC-seq is a little different\n",
    "macs2_file = \"EncodeStanfATACMotorNeuronAlnRep1\"\n",
    "cmds = [\"macs2 callpeak -t ../input_data/Epigenome/\"+cell_line+\"/\"+atac_file_rep1+\" \\\n",
    "-n \"+macs2_file+\".macs2 \\\n",
    "-f BAMPE \\\n",
    "--nomodel \\\n",
    "--keep-dup all \\\n",
    "--nolambda \\\n",
    "-g hs \\\n",
    "-p .1 \\\n",
    "--call-summits \\\n",
    "--outdir ../candidate_regions/macs2_results/\"+cell_line+\"/\", \\\n",
    "\n",
    "\"bedtools sort -faidx ../reference/chrom.sizes -i ../candidate_regions/macs2_results/\"+cell_line+\"/\"+macs2_file+\".macs2_peaks.narrowPeak > ../candidate_regions/macs2_results/\"+cell_line+\"/\"+macs2_file+\".macs2_peaks.narrowPeak.sorted\"]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(\"Executing command:\", cmd)\n",
    "\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "    # Wait for the process to finish and capture any errors\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    # Print any errors\n",
    "    if stderr:\n",
    "        print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make candidate regions\n",
    "Note that there are regions to exclude and to include. \\\n",
    "Also, they resized the elements to 500bp around the summit, and selected the top 150,000 peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index the bamfiles\n",
    "cmd = \"samtools index -faidx ../input_data/Epigenome/\"+cell_line+\"/\"+dnase_file_rep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### env: STARR\n",
    "macs2_file = \"EncodeStandfATACMotorNeuronAlnRep1\"\n",
    "cmd = \"python makeCandidateRegions.py \\\n",
    "--narrowPeak ../candidate_regions/macs2_results/\"+cell_line+\"/\"+macs2_file+\".macs2_peaks.narrowPeak.sorted \\\n",
    "--bam ../input_data/Epigenome/\"+cell_line+\"/\"+atac_file_rep1+\" \\\n",
    "--outDir ../candidate_regions/\"+cell_line+\"/ \\\n",
    "--chrom_sizes ../reference/chrom.sizes \\\n",
    "--regions_blocklist ../reference/hg38/hg38_lft_genome_ConsensusSignalArtifactRegions.bed \\\n",
    "--regions_includelist ../reference/hg38/RefSeqCurated.170308.bed.CollapsedGeneBounds.hg38.TSS500bp.bed  \\\n",
    "--peakExtendFromSummit 250 \\\n",
    "--nStrongestPeaks 150000\"\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "# Wait for the process to finish and capture any errors\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Print any errors\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize the PRO-cap defined enhancers to 500bp & add TSS to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if use PINTS called enhancers - should resize them to 500bp around the summit + combine with include + remove the exclude list\n",
    "def extending_500bp_from_summit(enhancer):\n",
    "    \"\"\" \n",
    "    Resize the PROcap defined enhancer (divergent/unidirectional) to 500bp.\n",
    "    \n",
    "    Parameter enhancer: Dataframe from pybedtools\n",
    "    \"\"\"\n",
    "    summit_index = ((enhancer[1]+enhancer[2])/2).astype(\"int64\")\n",
    "    start = summit_index - 250\n",
    "    end = summit_index + 250\n",
    "    enhancer[1] = start\n",
    "    enhancer[2] = end\n",
    "    return enhancer\n",
    "\n",
    "def merge_overlapping_rows(df):\n",
    "    merged_rows = []\n",
    "    previous_row = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if previous_row is None:\n",
    "            previous_row = row\n",
    "        else:\n",
    "            if row[0] == previous_row[0]:\n",
    "                if previous_row[2] > row[1]: # should be bigger instead of bigger than bc bed files are half-open, which means that [0,2), [2,3)\n",
    "                    previous_row[1] = min(previous_row[1], row[1])\n",
    "                    previous_row[2] = max(previous_row[2], row[2])\n",
    "                else:\n",
    "                    merged_rows.append(previous_row)\n",
    "                    previous_row = row\n",
    "            else:\n",
    "                merged_rows.append(previous_row)\n",
    "                previous_row = row\n",
    "\n",
    "    if previous_row is not None:\n",
    "        merged_rows.append(previous_row)\n",
    "    return pd.DataFrame(merged_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extra step to merge\n",
    "file1 = pybedtools.BedTool(\"../candidate_regions/Cerebral_cortex/CHTN22_v43_coding_200bp_e.bed\").to_dataframe(disable_auto_names=True, header=None)\n",
    "file2 = pybedtools.BedTool(\"../candidate_regions/Cerebral_cortex/HN21_v43_coding_200bp_e.bed\").to_dataframe(disable_auto_names=True, header=None)\n",
    "procap_enh = file1.merge(file2, how=\"outer\",on=[0,1,2]).sort_values(by=[0,1,2])\n",
    "print(procap_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procap_enh = pybedtools.BedTool(\"../candidate_regions/Neuronal_stem_cell/LUHMES.Li_v43_coding_200bp_e.bed\").to_dataframe(disable_auto_names=True, header=None)\n",
    "# print(procap_enh)\n",
    "\n",
    "output = extending_500bp_from_summit(procap_enh)\n",
    "\n",
    "include_list = pybedtools.BedTool(\"../reference/hg38/RefSeqCurated.170308.bed.CollapsedGeneBounds.hg38.TSS500bp.bed\").to_dataframe(disable_auto_names=True, header=None)\n",
    "output = output.merge(include_list, how=\"outer\",on=[0,1,2]).iloc[:,0:3].sort_values(by=[0,1,2])\n",
    "# print(output)\n",
    "\n",
    "result = merge_overlapping_rows(output)\n",
    "full_file = pybedtools.BedTool.from_dataframe(result)\n",
    "# print(full_file)\n",
    "\n",
    "### still need to exclude the exclude list\n",
    "exclude_list = pybedtools.BedTool(\"../reference/hg38/hg38_lft_genome_ConsensusSignalArtifactRegions.bed\")\n",
    "cov = full_file.coverage(exclude_list).to_dataframe()\n",
    "print(len(cov))\n",
    "overlapped = cov[cov[\"name\"] == 0].iloc[:,0:3]\n",
    "print(len(overlapped))\n",
    "overlapped.to_csv(\"../candidate_regions/Cerebral_cortex/PINTS_Cerebral_cortex_candidate_regions.bed\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify enhancer activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the gene expression table from RNA-seq tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the expression tsv file\n",
    "cell_line = \"Cerebral_cortex\"\n",
    "encode_idx = \"ENCFF928NYA\"\n",
    "\n",
    "file_path = \"../input_data/Expression/\"+cell_line+\"/\"+encode_idx+\".tsv\"\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "# print(df)\n",
    "\n",
    "gene_ids = df[\"gene_id\"].to_list()\n",
    "# print(gene_ids)\n",
    "print(len(gene_ids))\n",
    "\n",
    "tpm_values = df[\"TPM\"].to_list()\n",
    "print(len(tpm_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_name(gene_id, max_retries=3):\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            Entrez.email = \"yz2676@cornell.edu\"  # Provide your email address to comply with NCBI guidelines\n",
    "            handle = Entrez.efetch(db=\"gene\", id=gene_id, rettype=\"gb\", retmode=\"text\")\n",
    "            record = handle.read()\n",
    "            gene_name = record.split(\"\\n\")[1][3:]\n",
    "            return gene_name\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):\n",
    "                wait_time = 2**retry # Rate limit exceeded, implement backoff\n",
    "                print(f\"Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Error fetching information for Gene ID {gene_id}: {e}\")\n",
    "                error_ids.append(gene_id)\n",
    "                return \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to avoid unnecessary frequent query error, generate sub gene list\n",
    "n = 1000\n",
    "\n",
    "for index in range(0, int(len(gene_ids)/n)+1): # should have start from 0, but i have used 0 as a test - pre-generated\n",
    "    # if index == 59:\n",
    "    #     print(index)\n",
    "    #     print(len(gene_ids[n*index:n*index+n]))\n",
    "    unk_count = 0\n",
    "    gene_names = []\n",
    "    error_ids = []\n",
    "    for gene_id in gene_ids[n*index:n*index+n]:\n",
    "        name = get_gene_name(gene_id)\n",
    "        if name == \"?\":\n",
    "            name = \"unk{}\".format(unk_count)\n",
    "            unk_count +=1\n",
    "        gene_names.append(name)\n",
    "    tpm = pd.DataFrame(gene_names, columns=[\"GeneName\"])\n",
    "    tpm[\"tpm\"] = tpm_values[n*index:n*index+n]\n",
    "    print(tpm)\n",
    "    if index != int(len(gene_ids)/n):\n",
    "        assert len(tpm) == 1000\n",
    "    else:\n",
    "        print(\"last index length is:\", len(tpm))\n",
    "    tpm.to_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.{}.txt\".format(index), sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    error = pd.DataFrame(error_ids)\n",
    "    error.to_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".error.{}.txt\".format(index), sep=\"\\t\", index=False, header=False)\n",
    "    print(len(error_ids))\n",
    "    print(gene_names)\n",
    "    # if index == 1:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_replacement(index):\n",
    "    \"\"\"\n",
    "    Search the database agaib for the first time unknown indexes. Replace them in the TPM file and remove the error ids file.\n",
    "    \"\"\"\n",
    "    replacement = []\n",
    "    try:\n",
    "        error_ids = pd.read_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".error.{}.txt\".format(index), sep=\"\\n\", header=None)[0]\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"No error gene ids\")\n",
    "        cmds = [\"rm ../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".error.{}.txt\".format(index)]\n",
    "        for cmd in cmds:\n",
    "            os.system(cmd)\n",
    "        return\n",
    "    # print(error_ids)\n",
    "    for error_id in error_ids:\n",
    "        print(error_id)\n",
    "        replacement.append(get_gene_name(error_id))\n",
    "\n",
    "    print(replacement)\n",
    "\n",
    "    assert len(replacement) == len(error_ids), \"Length doesn't match\"\n",
    "\n",
    "    file = pd.read_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.{}.txt\".format(index), sep=\"\\t\", header=None)\n",
    "    # print(file)\n",
    "    unk_list = []\n",
    "    for i in range(len(replacement)):\n",
    "        unk_list.append(\"unk{}\".format(i))\n",
    "\n",
    "    # Specify the columb to replace values in\n",
    "    columb_to_replace = 0\n",
    "\n",
    "    # Replace unk with values from the new list\n",
    "    file[columb_to_replace] = file[columb_to_replace].replace(unk_list, value=replacement)\n",
    "\n",
    "    ### now remove the ones where the database doesn't have their informatgXb\n",
    "    no_sum = file[0] == \" Error occurred: cannot get document summary\"\n",
    "    file = file[-no_sum]\n",
    "    print(len(file))\n",
    "    file.to_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.{}.txt\".format(index), sep=\"\\t\", index=False, header=False)\n",
    "    cmds = [\"rm ../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".error.{}.txt\".format(index)]\n",
    "    for cmd in cmds:\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0,60): # modify with the number of sub-files\n",
    "    error_replacement(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finally, merge all files into one\n",
    "n = 1000\n",
    "\n",
    "file = pd.read_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.0.txt\", sep=\"\\t\", header=None)\n",
    "# print(len(file))\n",
    "for index in range(1, int(len(gene_ids)/n)+1):\n",
    "    file1 = pd.read_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.{}.txt\".format(index), sep=\"\\t\", header=None)\n",
    "    # print(len(file1))\n",
    "    file = pd.concat([file, file1])\n",
    "\n",
    "print(len(file))\n",
    "file.to_csv(\"../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.txt\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove all the intermediate files\n",
    "for index in range(0, int(len(gene_ids)/n)+1):\n",
    "    cmds = [\"rm ../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+encode_idx+\".TPM.{}.txt\".format(index)]\n",
    "    for cmd in cmds:\n",
    "        os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count DNase-seq and H3K27ac ChIP-seq reads in candidate enhancer regions\n",
    "Also makes GeneList.txt, which counts reads in gene bodies and promoter regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the candidate_enhancer_regions accordingly\n",
    "# pints: --candidate_enhancer_regions ../candidate_regions/\"+cell_line+\"/PINTS_\"+cell_line+\"_candidate_regions.bed \\\n",
    "# DHS: --candidate_enhancer_regions ../candidate_regions/\"+cell_line+\"/\"+macs2_file+\".macs2_peaks.narrowPeak.sorted.candidateRegions.bed \\\n",
    "# if H3K27ac doesn't exist, use DNase only - according to manual\n",
    "# --H3K27ac ../input_data/Epigenome/\"+cell_line+\"/\"+h3k27ac+\" \\\n",
    "\n",
    "macs2_file = \"EncodeUwDnaseCerebralCortexAlnRep2\"\n",
    "typ = \"pints\"\n",
    "\n",
    "cmd = \"python run.neighborhoods.py \\\n",
    "--candidate_enhancer_regions ../candidate_regions/\"+cell_line+\"/PINTS_\"+cell_line+\"_candidate_regions.bed \\\n",
    "--genes ../reference/hg38/RefSeqCurated.170308.bed.CollapsedGeneBounds.hg38.bed \\\n",
    "--DHS ../input_data/Epigenome/\"+cell_line+\"/\"+dnase_file_rep1+\",../input_data/Epigenome/\"+cell_line+\"/\"+dnase_file_rep2+\" \\\n",
    "--H3K27ac ../input_data/Epigenome/\"+cell_line+\"/\"+h3k27ac+\" \\\n",
    "--expression_table ../input_data/Expression/\"+cell_line+\"/\"+cell_line+\".\"+tpm+\".TPM.txt \\\n",
    "--chrom_sizes ../reference/chrom.sizes \\\n",
    "--ubiquitously_expressed_genes ../reference/UbiquitouslyExpressedGenesHG19.txt \\\n",
    "--cellType \"+cell_line+\" \\\n",
    "--outdir ../ABC_output/Neighborhoods/\"+cell_line+\"/\"+typ+\"/\"\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "# Wait for the process to finish and capture any errors\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Print any errors\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the ABC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download HiC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download hic matrix file from juicebox - used VC normalization\n",
    "cmd = \"python juicebox_dump.py \\\n",
    "--hic_file https://www.encodeproject.org/files/ENCFF080DPJ/@@download/ENCFF080DPJ.hic \\\n",
    "--juicebox 'java -jar juicer_tools_2.13.06.jar' \\\n",
    "--outdir ../input_data/HiC/K562/ \\\n",
    "--chromosome-prefix chr\"\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "# Wait for the process to finish and capture any errors\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Print any errors\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit HiC data to powerlaw model and extract parameters\n",
    "cmd = \"python compute_powerlaw_fit_from_hic.py \\\n",
    "--hicDir ../input_data/HiC/Astrocyte/ \\\n",
    "--outDir ../input_data/HiC/Astrocyte/powerlaw/ \\\n",
    "--maxWindow 1000000 \\\n",
    "--minWindow 5000 \\\n",
    "--resolution 5000\"\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "# Wait for the process to finish and capture any errors\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Print any errors\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### takes up a long time to run, try to do this step in command line\n",
    "enh_infer_type = \"pints\"\n",
    "threshold = \"0.05\"\n",
    "cmd = \"python predict.py \\\n",
    "--enhancers ../ABC_output/Neighborhoods/\"+cell_line+\"/\"+enh_infer_type+\"/EnhancerList.txt \\\n",
    "--genes ../ABC_output/Neighborhoods/\"+cell_line+\"/\"+enh_infer_type+\"/GeneList.txt \\\n",
    "--HiCdir ../input_data/HiC/\"+cell_line+\"/ \\\n",
    "--chrom_sizes ../reference/chrom.sizes \\\n",
    "--hic_resolution 5000 \\\n",
    "--scale_hic_using_powerlaw \\\n",
    "--threshold \"+threshold+\" \\\n",
    "--cellType \"+cell_line+\" \\\n",
    "--outdir ../ABC_output/Predictions/\"+cell_line+\"/\"+enh_infer_type+\"/\"+threshold+\"/ \\\n",
    "--make_all_putative | tee -ai ../ABC_output/Predictions/\"+cell_line+\"/\"+enh_infer_type+\"/\"+threshold+\"/predict_output.log\"\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line.decode(\"utf-8\"), end=\"\")\n",
    "\n",
    "# Wait for the process to finish and capture any errors\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Print any errors\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABC candidate regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "categories = ['Astrocytes', 'Neuronal Progenitor Cells', 'Excitatory Cortical Neurons', 'Cerebellum', 'Cerebral Cortex']\n",
    "values_dhs = [151686, 135976, 223156, 142519, 150515]\n",
    "values_pints = [30620, 38681, 42307, 36334, 49879]\n",
    "\n",
    "colors_dhs = [\"moccasin\" if category in [\"Cerebral Cortex\", \"Cerebellum\"] else \"lightblue\" for category in categories]\n",
    "colors_pints = [\"orange\" if category in [\"Cerebral Cortex\", \"Cerebellum\"] else \"deepskyblue\" for category in categories]\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create horizontal bar chart\n",
    "# Set the bar positions\n",
    "bar_width = 0.35\n",
    "indices = np.arange(len(categories))\n",
    "\n",
    "# Create horizontal bar charts\n",
    "bars_pints = ax.barh(indices + bar_width, values_pints, bar_width, label='PINTS', color=colors_pints)\n",
    "bars_dhs = ax.barh(indices, values_dhs, bar_width, label='DHS', color=colors_dhs)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Number of Candidate Enhancer Elements', fontsize=14)\n",
    "ax.set_title('Candidate Enhancer Elements in ASD-associated Brain Cells and Tissues', fontsize=16)\n",
    "\n",
    "def add_bar_labels(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label_x_pos = 16000\n",
    "        text_color = 'black'\n",
    "        ax.text(label_x_pos, bar.get_y() + bar.get_height() / 2, f'{width}', ha='center', va='center', fontsize=12, color=text_color)\n",
    "\n",
    "add_bar_labels(bars_dhs)\n",
    "add_bar_labels(bars_pints)\n",
    "\n",
    "# Add the legend with a larger font size\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "ax.set_yticks([r + bar_width/2 for r in indices])\n",
    "ax.set_yticklabels(categories, fontsize=14)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of different predicted E-G linkage using different HiC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_content = pd.read_csv(\"../ABC_output/Predictions/average/GenePredictionStats.txt\", delimiter=\"\\t\")\n",
    "# print(avg_content)\n",
    "mean_enh = avg_content[\"nDistalEnhancersPredicted\"].mean()\n",
    "median_enh = avg_content[\"nDistalEnhancersPredicted\"].median()\n",
    "# max_enh = avg_content[\"nDistalEnhancersPredicted\"].max()\n",
    "\n",
    "# Plot the distributgXb using seaborn and matplotlib\n",
    "sns.histplot(avg_content[\"nDistalEnhancersPredicted\"])  # kde=True adds a kernel density estgmate\n",
    "plt.text(avg_content[\"nDistalEnhancersPredicted\"].max()*0.8, 8000, f'Mean: {mean_enh:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.text(avg_content[\"nDistalEnhancersPredicted\"].max()*0.8, 7000, f'Median: {median_enh}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('DistributgXb of Predicted Distal Enhancers in avg-HiC')\n",
    "plt.xlabel('Number of enhancers per gene')\n",
    "plt.ylabel('Number of genes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_content = pd.read_csv(\"../ABC_output/PredictgXbs/GenePredictionStats.txt\", delimiter=\"\\t\")\n",
    "# print(sc_content)\n",
    "mean_enh = sc_content[\"nDistalEnhancersPredicted\"].mean()\n",
    "median_enh = sc_content[\"nDistalEnhancersPredicted\"].median()\n",
    "# max_enh = sc_content[\"nDistalEnhancersPredicted\"].max()\n",
    "\n",
    "# Plot the distributgXb using seaborn and matplotlib\n",
    "sns.histplot(sc_content[\"nDistalEnhancersPredicted\"])  # kde=True adds a kernel density estgmate\n",
    "plt.text(sc_content[\"nDistalEnhancersPredicted\"].max()*0.8, 8000, f'Mean: {mean_enh:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.text(sc_content[\"nDistalEnhancersPredicted\"].max()*0.8, 7000, f'Median: {median_enh}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('Distribution of Predicted Distal Enhancers in astrocyte-HiC')\n",
    "plt.xlabel('Number of enhancers per gene')\n",
    "plt.ylabel('Number of genes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_enh = pd.read_csv(\"../ABC_output/PredictgXbs/EnhancerPredictionFull.txt\", delimiter=\"\\t\")\n",
    "# print(sc_enh)\n",
    "\n",
    "grouped = sc_enh.groupby(['chr', 'start', 'end'])\n",
    "count_sc_enh = grouped.size().reset_index(name='Count')\n",
    "# print(count_sc_enh)\n",
    "\n",
    "mean_gen = count_sc_enh[\"Count\"].mean()\n",
    "median_gen = count_sc_enh[\"Count\"].median()\n",
    "# print(\"max:\", count_sc_enh[\"Count\"].max())\n",
    "\n",
    "## how to plot this: separate 1-5, 6+ or together\n",
    "subset_data = count_sc_enh[(count_sc_enh[\"Count\"] >=0) & (count_sc_enh[\"Count\"] <=5)]\n",
    "# print(subset_data)\n",
    "bin_edges = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "plt.hist(count_sc_enh[\"Count\"], bins=count_sc_enh[\"Count\"].nunique(),edgecolor='black', align=\"mid\") # kde=True adds a kernel density estgmate\n",
    "plt.text(count_sc_enh[\"Count\"].max()*0.8, 30000, f'Mean: {mean_gen:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.text(count_sc_enh[\"Count\"].max()*0.8, 27500, f'Median: {median_gen}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('Distribution of Genes for Predicted Enhancers in astrocyte-HiC')\n",
    "plt.xlabel('Number of genes per enhancer')\n",
    "plt.ylabel('Number of enhancers')\n",
    "plt.show()\n",
    "\n",
    "# rest_data = count_sc_enh[~((count_sc_enh[\"Count\"] >=0) & (count_sc_enh[\"Count\"] <=5))]\n",
    "# sns.histplot(rest_data[\"Count\"]) # kde=True adds a kernel density estgmate\n",
    "# # plt.text(sc_content[\"nDistalEnhancersPredicted\"].max()*0.8, 8000, f'Mean: {mean_enh:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "# # plt.text(sc_content[\"nDistalEnhancersPredicted\"].max()*0.8, 7000, f'Median: {median_enh}', verticalalignment='bottom', horizontalalignment='right')\n",
    "# plt.title('Distribution of Genes for Predicted Enhancers in astrocyte-HiC')\n",
    "# plt.xlabel('Number of genes per enhancer')\n",
    "# plt.ylabel('Number of enhancers')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_enh = pd.read_csv(\"../ABC_output/PredictgXbs/average/EnhancerPredicionsFull.txt\", delimiter=\"\\t\")\n",
    "# print(sc_enh)\n",
    "\n",
    "grouped = sc_enh.groupby(['chr', 'start', 'end'])\n",
    "count_sc_enh = grouped.size().reset_index(name='Count')\n",
    "# print(count_sc_enh)\n",
    "\n",
    "mean_gen = count_sc_enh[\"Count\"].mean()\n",
    "median_gen = count_sc_enh[\"Count\"].median()\n",
    "# print(\"max:\", count_sc_enh[\"Count\"].max())\n",
    "\n",
    "## how to plot this: separate 1-5, 6+ or together\n",
    "subset_data = count_sc_enh[(count_sc_enh[\"Count\"] >=0) & (count_sc_enh[\"Count\"] <=5)]\n",
    "# print(subset_data)\n",
    "# bin_edges = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "plt.hist(count_sc_enh[\"Count\"], bins=count_sc_enh[\"Count\"].nunique(),edgecolor='black', align=\"mid\") # kde=True adds a kernel density estgmate\n",
    "plt.text(count_sc_enh[\"Count\"].max()*0.8, 17500, f'Mean: {mean_gen:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.text(count_sc_enh[\"Count\"].max()*0.8, 16250, f'Median: {median_gen}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('DistributgXb of Genes for Predicted Enhancers in average-HiC')\n",
    "plt.xlabel('Number of genes per enhancer')\n",
    "plt.ylabel('Number of enhancers')\n",
    "plt.show()\n",
    "\n",
    "# rest_data = count_sc_enh[~((count_sc_enh[\"Count\"] >=0) & (count_sc_enh[\"Count\"] <=5))]\n",
    "# sns.histplot(rest_data[\"Count\"]) # kde=True adds a kernel density estgmate\n",
    "# # plt.text(sc_content[\"nDistalEnhancersPredicted\"].max()*0.8, 8000, f'Mean: {mean_enh:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "# # plt.text(sc_content[\"nDistalEnhancersPredicted\"].max()*0.8, 7000, f'Median: {median_enh}', verticalalignment='bottom', horizontalalignment='right')\n",
    "# plt.title('DistributgXb of Genes for Predicted Enhancers in astrocyte-HiC')\n",
    "# plt.xlabel('Number of genes per enhancer')\n",
    "# plt.ylabel('Number of enhancers')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pints_content = pd.read_csv(\"../ABC_output/PredictgXbs/PINTS/GenePredictgXbStats.txt\", delimiter=\"\\t\")\n",
    "# print(pints_content)\n",
    "mean_enh = pints_content[\"nDistalEnhancersPredicted\"].mean()\n",
    "median_enh = pints_content[\"nDistalEnhancersPredicted\"].median()\n",
    "# max_enh = pints_content[\"nDistalEnhancersPredicted\"].max()\n",
    "\n",
    "# Plot the distributgXb using seaborn and matplotlib\n",
    "sns.histplot(pints_content[\"nDistalEnhancersPredicted\"])  # kde=True adds a kernel density estgmate\n",
    "plt.text(pints_content[\"nDistalEnhancersPredicted\"].max()*0.8, 5000, f'Mean: {mean_enh:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.text(pints_content[\"nDistalEnhancersPredicted\"].max()*0.8, 4500, f'Median: {median_enh}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('DistributgXb of Predicted Distal Enhancers in astrocyte-HiC using PINTS-called enhancers')\n",
    "plt.xlabel('Number of enhancers per gene')\n",
    "plt.ylabel('Number of genes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_enh = pd.read_csv(\"../ABC_output/PredictgXbs/PINTS/EnhancerPredictgXbsFull.txt\", delimiter=\"\\t\")\n",
    "# print(sc_enh)\n",
    "\n",
    "grouped = sc_enh.groupby(['chr', 'start', 'end'])\n",
    "count_sc_enh = grouped.size().reset_index(name='Count')\n",
    "# print(count_sc_enh)\n",
    "\n",
    "mean_gen = count_sc_enh[\"Count\"].mean()\n",
    "median_gen = count_sc_enh[\"Count\"].median()\n",
    "# print(\"max:\", count_sc_enh[\"Count\"].max())\n",
    "\n",
    "## how to plot this: separate 1-5, 6+ or together\n",
    "subset_data = count_sc_enh[(count_sc_enh[\"Count\"] >=0) & (count_sc_enh[\"Count\"] <=5)]\n",
    "# print(subset_data)\n",
    "bin_edges = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "plt.hist(count_sc_enh[\"Count\"], bins=count_sc_enh[\"Count\"].nunique(),edgecolor='black', align=\"mid\") # kde=True adds a kernel density estgmate\n",
    "plt.text(count_sc_enh[\"Count\"].max()*0.8, 700, f'Mean: {mean_gen:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.text(count_sc_enh[\"Count\"].max()*0.8, 600, f'Median: {median_gen}', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('DistributgXb of Genes for Predicted Enhancers in astrocyte-HiC using PINTS-called enhancers')\n",
    "plt.xlabel('Number of genes per enhancer')\n",
    "plt.ylabel('Number of enhancers')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macs-py2.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
